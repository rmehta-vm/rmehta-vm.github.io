---
layout: single
title: "Machine Learning for Smarter Vulnerability Management"
order: 130

---
---

## Why This Project Matters

Traditional vulnerability management relies on **rules and static scores** (CVSS, CVE lists, manual checks). While useful, these approaches miss context and often overwhelm teams with noise.

This project demonstrates how **Machine Learning (ML)** ‚Äî especially **Random Forest models** ‚Äî can make vulnerability management smarter by learning patterns from real-world data.

Instead of just listing vulnerabilities, ML helps answer:  
- *Which ones are actually risky?*  
- *Which ones need urgent attention?*  
- *Which ones can wait?*  

---

## 1) SBOM Vulnerability Tool (`sbomvul-tool`)

### What It Does
- Takes an SBOM (Software Bill of Materials)  
- Enriches packages with metadata (age, dependencies, EOL status, etc.)  
- Predicts if a package is at risk ‚Äî even without a known CVE  
- Produces JSON output with risk predictions and explanations  

### Why It‚Äôs Important
- Many risks never make it to CVE databases.  
- Old or unsupported packages (EOL) can still be dangerous.  
- By combining SBOM + ML, teams can see **beyond CVE-based blind spots**.  

### Example Insight
A Python package with no CVE but marked EOL and unused for years can be flagged by the model.  
This gives developers early warning signs, instead of waiting for a CVE to be published.  

üîó **Usage details and examples** ‚Üí https://github.com/rmehta-vm/sbomvul-tool

---

## 2) CVE Risk Tool (`cve-risk-tool`)

### What It Does
- Prioritizes **known CVEs** based on richer context  
- Factors include CVSS vector, exploit availability, EPSS score, and runtime presence  
- Outputs predictions with confidence and reasoning  

### Why It‚Äôs Important
- Not all CVEs with a high CVSS score are urgent.  
- The model learns to combine multiple factors:  
  - *Remote exploitability*  
  - *Is an exploit publicly available?*  
  - *How likely is it to be exploited (EPSS)?*  
  - *Is the vulnerable component actually loaded at runtime?*  

### Example Insight
- **High Risk**: CVE is remotely exploitable, has a public exploit, and is actively loaded.  
- **Low Risk**: CVE looks severe on paper (AV:N) but isn‚Äôt exploited, EPSS is low, and it‚Äôs not loaded in runtime.  

üîó **Usage details and examples** ‚Üí https://github.com/rmehta-vm/cve-risk-tool

---

## Why Machine Learning?

- **Rule-based logic is rigid** ‚Äî it can‚Äôt adapt to new patterns.  
- **ML models learn from data** ‚Äî they balance multiple signals, reduce false positives, and get better with feedback.  
- **Random Forest** was chosen over simpler models (like Logistic Regression) for its ability to handle diverse features and non-linear risk patterns.  

In practice:  
- Logistic Regression: ~70% accuracy  
- Random Forest: ~90% accuracy  

---

## Limitations

- Models are only as good as their training data.  
- Edge cases may still be missed without diverse examples.  
- Expert oversight is critical ‚Äî ML assists, it doesn‚Äôt replace human judgment.  

---

## Future Enhancements

- Add **runtime context**: imports, process memory, container introspection.  
- Extend features: patch availability, zero-day flags, license/maintainer metadata.  
- Support more ecosystems beyond Python (Java, Go, Node.js, etc.).  
- Integrate feedback loops so the model improves with each run.  

---

## The Big Picture

Together, the two tools form a **complementary system**:  
- **sbomvul-tool** ‚Üí Looks at package health and risk, even without CVEs.  
- **cve-risk-tool** ‚Üí Ranks known CVEs using richer context.  

This shifts vulnerability management from:  
- Static CVE lists ‚Üí **Context-aware scoring**  
- Guesswork triage ‚Üí **Data-driven prioritization**  
- One-time scans ‚Üí **Continuous learning and improvement**  

---

## Final Word

The code here is intentionally lightweight, but the **value lies in the approach**:  
- Teach models to ‚Äúthink‚Äù like analysts  
- Reduce noise and focus on what matters  
- Build security systems that learn over time 
